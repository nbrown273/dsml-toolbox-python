{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "The Pandas library is essentially a one-stop shop for common workflows in data science. It provides the basic toolset needed for data cleaning, feature engineering, statistical analysis, and visualizations in one place. Sometimes the basic toolset is enough, but in cases where it is not, the pandas library is built on top of numpy which allows easy integration with more specialized libraries like scikit-learn. Essentially, as long as it makes sense to represent your data in tables you should consider using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "The main data structure of Pandas is the DataFrame, which is a 2-D labeled, table like structure. It is composed of several Data Series which are 1-D homogeneous-typed arrays. Understanding how to work with these two structures is the core of working with Pandas. The first step is acquiring a dataframe (or series) to work with.\n",
    "\n",
    "One way to get a dataframe is by importing from another data source. Pandas supports the ability to work with many common file formats (csv, excel, json, hdf5, ...) and databases. The cell below pulls a csv from the specified url and imports it in as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Let's experiment creating a dataframe from JSON files. The simulated datasets are available in the module folder as `simulated_form<id>.json` files. Each file is the same dataset, but in a different json format. Use the `read_json` Pandas method to load three or more of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = None # fill in these lines\n",
    "df2 = None\n",
    "df3 = None\n",
    "\n",
    "for df in [df1, df2, df3]:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to acquire DataFrames or Series is to literally construct them from existing collections. Base collections could be native Python lists, numpy arrays, or dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, 3, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.randn(10,4), columns = ['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"PI\": 3.14,\n",
    "    \"Radius\": np.arange(5),\n",
    "    \"Size\": pd.Categorical([\"S\", \"S\", \"S\", \"L\", \"L\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data\n",
    "\n",
    "After you've created a data frame the next natural step is exploring it's contents. There are several helpful methods that can be used for viewing different attributes. Below are just a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (150, 5)\n",
      "Index = RangeIndex(start=0, stop=150, step=1)\n",
      "Columns = Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'species'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape = {iris.shape}')\n",
    "print(f'Index = {iris.index}')\n",
    "print(f'Columns = {iris.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
